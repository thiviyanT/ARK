# Configuration for training an autoregressive model on WD articles dataset

# Model architecture
model_type: autoreg
d_model: 512
d_latent: 128
n_heads: 8
n_layers: 12

# Training parameters
batch_size: 16
learning_rate: 0.0001
num_epochs: 150
beta0: 0.1
beta1: 1.0

# Dataset parameters
dataset: wd-articles
shuffle_train: false
use_padding: true
triple_order: keep #keep for keeping the dataset order as is or alpha_name for sorting categorically 

# Generation parameters
num_diversity_samples: 100
num_generated_test_graphs: 100
num_generated_latent_graphs: 100
sample_frac: 0.01
beam_width: 4

# Optimization settings
lr_scheduler: true
save_every: 50
resume_from_checkpoint: false
checkpoint_path: checkpoints/autoreg_wd_articles.pt

# Experiment tracking
experiment_name: autoreg_vae_wd_articles
verify_every: 20

# Evaluation settings
use_test_for_final_eval: true  

#Compression bits estimation
compression_log_every: 20
