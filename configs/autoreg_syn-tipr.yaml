# Configuration for training an autoregressive model on synthetic tipr dataset


#Model architecture
model_type: ARK #can be ARK or t-ARK, SAIL or t-SAIL
d_model: 1024
d_latent: 32
n_heads: 16
n_layers: 3

#Training parameters
batch_size: 256
learning_rate: 0.0001
# num_epochs: 200
num_epochs: 100
beta0: 0.1
beta1: 1.0

#Dataset parameters
dataset: syn-tipr
shuffle_train: false
use_padding: false
triple_order: keep #keep for keeping the dataset order as is or alpha_name for sorting categorically 
permute_triples: true  # whether to permute triples in each graph

#Generation parameters
num_diversity_samples: 10000
num_generated_test_graphs: 10000
num_generated_latent_graphs: 10000
sample_frac: 0.1
beam_width: 4

#Optimization settings
lr_scheduler: true
save_every: 100
resume_from_checkpoint: false
checkpoint_path: checkpoints2/tipr/dec_only/GRU/autoreg_syn_tipr.pt

#Experiment tracking
experiment_name: autoreg_vae_syn_tipr_dec_only_TRF
verify_every: 25

#Evaluation settings
use_test_for_final_eval: true  

#Compression bits estimation
compression_log_every: 25
