# Configuration for training an autoregressive model on synthetic tipr dataset


#Model architecture
model_type: autoreg
d_model: 1024
d_latent: 32
n_heads: 16
n_layers: 3

#Training parameters
batch_size: 256
learning_rate: 0.0001
num_epochs: 300
beta0: 0.1
beta1: 1.0

#Dataset parameters
dataset: syn-tipr
shuffle_train: false
use_padding: false
triple_order: keep #keep for keeping the dataset order as is or alpha_name for sorting categorically 

#Generation parameters
num_diversity_samples: 10000
num_generated_test_graphs: 1000
num_generated_latent_graphs: 1000
sample_frac: 0.1
beam_width: 4

#Optimization settings
lr_scheduler: true
save_every: 50
resume_from_checkpoint: false
checkpoint_path: checkpoints/autoreg_syn_tipr.pt

#Experiment tracking
experiment_name: autoreg_vae_syn_tipr
verify_every: 10

#Evaluation settings
use_test_for_final_eval: true  

#Compression bits estimation
compression_log_every: 10  
