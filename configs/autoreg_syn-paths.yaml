# Configuration for training an autoregressive model on synthetic paths dataset

#Model architecture
model_type: autoreg
d_model: 512
d_latent: 10
n_heads: 4
n_layers: 3

#Training parameters
batch_size: 256
learning_rate: 0.0001
num_epochs: 300
beta0: 0.1
beta1: 1.0

#Dataset parameters
dataset: syn-paths
shuffle_train: false
use_padding: false
triple_order: keep #keep for keeping the dataset order as is or alpha_name for sorting categorically 

#Generation parameters
num_diversity_samples: 10000
num_generated_test_graphs: 1000
num_generated_latent_graphs: 1000
sample_frac: 0.1
beam_width: 4

#Optimization Parameters
lr_scheduler: true
save_every: 50
resume_from_checkpoint: false
checkpoint_path: checkpoints/autoreg_syn_paths.pt 

#Experiment tracking
verify_every: 10
experiment_name: autoreg_vae_syn_paths

#Evaluation settings
use_test_for_final_eval: true  

#Compression bits estimation
compression_log_every: 10

#ablation study settings
ablation_encoder: MLP 
ablation_decoder: GRU

